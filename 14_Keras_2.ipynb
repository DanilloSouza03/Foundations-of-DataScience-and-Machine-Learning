{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "**Keras - Classificação de Textos**\n",
    "\n",
    "*Autor: Danillo de Souza*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 189, 141)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0]), len(X_train[1]),len(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um dicionário mapeando palavras em índices inteiros\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# Os primeiros índices são reservados\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> begins better than it ends funny that the russian submarine crew <UNK> all other actors it's like those scenes where documentary shots br br spoiler part the message <UNK> was contrary to the whole story it just does not <UNK> br br\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(X_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "        value=word_index[\"<PAD>\"],\n",
    "        padding='post',\n",
    "        maxlen=256)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "       value=word_index[\"<PAD>\"],\n",
    "       padding='post',\n",
    "       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 256)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0]), len(X_train[1]),len(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          160000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = X_train[:10000]\n",
    "partial_x_train = X_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "30/30 [==============================] - 2s 50ms/step - loss: 0.6920 - accuracy: 0.5790 - val_loss: 0.6903 - val_accuracy: 0.6602\n",
      "Epoch 2/40\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.6870 - accuracy: 0.6626 - val_loss: 0.6830 - val_accuracy: 0.7309\n",
      "Epoch 3/40\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 0.6750 - accuracy: 0.7289 - val_loss: 0.6667 - val_accuracy: 0.6910\n",
      "Epoch 4/40\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.6522 - accuracy: 0.7452 - val_loss: 0.6403 - val_accuracy: 0.7587\n",
      "Epoch 5/40\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.6177 - accuracy: 0.7827 - val_loss: 0.6037 - val_accuracy: 0.7701\n",
      "Epoch 6/40\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.5734 - accuracy: 0.8032 - val_loss: 0.5615 - val_accuracy: 0.8051\n",
      "Epoch 7/40\n",
      "30/30 [==============================] - 2s 62ms/step - loss: 0.5245 - accuracy: 0.8321 - val_loss: 0.5151 - val_accuracy: 0.8209\n",
      "Epoch 8/40\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 0.4752 - accuracy: 0.8495 - val_loss: 0.4725 - val_accuracy: 0.8314\n",
      "Epoch 9/40\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.4294 - accuracy: 0.8656 - val_loss: 0.4347 - val_accuracy: 0.8468\n",
      "Epoch 10/40\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.3903 - accuracy: 0.8751 - val_loss: 0.4037 - val_accuracy: 0.8548\n",
      "Epoch 11/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.3572 - accuracy: 0.8845 - val_loss: 0.3798 - val_accuracy: 0.8596\n",
      "Epoch 12/40\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.3293 - accuracy: 0.8915 - val_loss: 0.3593 - val_accuracy: 0.8668\n",
      "Epoch 13/40\n",
      "30/30 [==============================] - 2s 75ms/step - loss: 0.3061 - accuracy: 0.8977 - val_loss: 0.3437 - val_accuracy: 0.8707\n",
      "Epoch 14/40\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.2866 - accuracy: 0.9027 - val_loss: 0.3311 - val_accuracy: 0.8738\n",
      "Epoch 15/40\n",
      "30/30 [==============================] - 1s 43ms/step - loss: 0.2684 - accuracy: 0.9084 - val_loss: 0.3211 - val_accuracy: 0.8751\n",
      "Epoch 16/40\n",
      "30/30 [==============================] - 1s 43ms/step - loss: 0.2532 - accuracy: 0.9131 - val_loss: 0.3135 - val_accuracy: 0.8779\n",
      "Epoch 17/40\n",
      "30/30 [==============================] - 2s 53ms/step - loss: 0.2396 - accuracy: 0.9186 - val_loss: 0.3059 - val_accuracy: 0.8791\n",
      "Epoch 18/40\n",
      "30/30 [==============================] - 2s 64ms/step - loss: 0.2270 - accuracy: 0.9230 - val_loss: 0.3005 - val_accuracy: 0.8815\n",
      "Epoch 19/40\n",
      "30/30 [==============================] - 2s 55ms/step - loss: 0.2156 - accuracy: 0.9267 - val_loss: 0.2962 - val_accuracy: 0.8825\n",
      "Epoch 20/40\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.2055 - accuracy: 0.9305 - val_loss: 0.2926 - val_accuracy: 0.8813\n",
      "Epoch 21/40\n",
      "30/30 [==============================] - 1s 45ms/step - loss: 0.1958 - accuracy: 0.9344 - val_loss: 0.2923 - val_accuracy: 0.8807\n",
      "Epoch 22/40\n",
      "30/30 [==============================] - 1s 47ms/step - loss: 0.1873 - accuracy: 0.9380 - val_loss: 0.2875 - val_accuracy: 0.8838\n",
      "Epoch 23/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.1793 - accuracy: 0.9417 - val_loss: 0.2860 - val_accuracy: 0.8846\n",
      "Epoch 24/40\n",
      "30/30 [==============================] - 1s 44ms/step - loss: 0.1707 - accuracy: 0.9451 - val_loss: 0.2851 - val_accuracy: 0.8860\n",
      "Epoch 25/40\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.1635 - accuracy: 0.9485 - val_loss: 0.2854 - val_accuracy: 0.8837\n",
      "Epoch 26/40\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.1572 - accuracy: 0.9519 - val_loss: 0.2848 - val_accuracy: 0.8844\n",
      "Epoch 27/40\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.1501 - accuracy: 0.9545 - val_loss: 0.2848 - val_accuracy: 0.8859\n",
      "Epoch 28/40\n",
      "30/30 [==============================] - 2s 65ms/step - loss: 0.1441 - accuracy: 0.9565 - val_loss: 0.2865 - val_accuracy: 0.8840\n",
      "Epoch 29/40\n",
      "30/30 [==============================] - 2s 57ms/step - loss: 0.1381 - accuracy: 0.9589 - val_loss: 0.2869 - val_accuracy: 0.8840\n",
      "Epoch 30/40\n",
      "30/30 [==============================] - 2s 58ms/step - loss: 0.1328 - accuracy: 0.9613 - val_loss: 0.2880 - val_accuracy: 0.8848\n",
      "Epoch 31/40\n",
      "30/30 [==============================] - 1s 48ms/step - loss: 0.1276 - accuracy: 0.9636 - val_loss: 0.2898 - val_accuracy: 0.8843\n",
      "Epoch 32/40\n",
      "30/30 [==============================] - 2s 56ms/step - loss: 0.1225 - accuracy: 0.9654 - val_loss: 0.2918 - val_accuracy: 0.8840\n",
      "Epoch 33/40\n",
      "30/30 [==============================] - 1s 38ms/step - loss: 0.1178 - accuracy: 0.9675 - val_loss: 0.2934 - val_accuracy: 0.8850\n",
      "Epoch 34/40\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.1134 - accuracy: 0.9687 - val_loss: 0.2956 - val_accuracy: 0.8848\n",
      "Epoch 35/40\n",
      "30/30 [==============================] - 1s 38ms/step - loss: 0.1088 - accuracy: 0.9707 - val_loss: 0.2998 - val_accuracy: 0.8837\n",
      "Epoch 36/40\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.1050 - accuracy: 0.9716 - val_loss: 0.3008 - val_accuracy: 0.8843\n",
      "Epoch 37/40\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 0.1012 - accuracy: 0.9726 - val_loss: 0.3037 - val_accuracy: 0.8839\n",
      "Epoch 38/40\n",
      "30/30 [==============================] - 1s 38ms/step - loss: 0.0972 - accuracy: 0.9753 - val_loss: 0.3087 - val_accuracy: 0.8821\n",
      "Epoch 39/40\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.0937 - accuracy: 0.9765 - val_loss: 0.3105 - val_accuracy: 0.8832\n",
      "Epoch 40/40\n",
      "30/30 [==============================] - 1s 43ms/step - loss: 0.0901 - accuracy: 0.9769 - val_loss: 0.3136 - val_accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238bf910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=40,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "newText = \"this film is very good and has very good actors\"\n",
    "newText2 = \"the film is the worst i wouldn't watch again worst worst worst worst\"\n",
    "newText3 = \"this film is horrible\"\n",
    "newText4 = \"the film is quite good but i expected more to have high level actors so i would not recommend this film\"\n",
    "newText = newText.split()\n",
    "newText2 = newText2.split()\n",
    "newText3 = newText3.split()\n",
    "newText4 = newText4.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14  22   9 527   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "list = []\n",
    "def localizaCode(code):\n",
    "    return word_index[code]\n",
    "for i in newText3:\n",
    "    list.append(localizaCode(i))\n",
    "list = keras.preprocessing.sequence.pad_sequences([list], padding='post', maxlen=256)\n",
    "\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(list)\n",
    "np.round(pred[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
